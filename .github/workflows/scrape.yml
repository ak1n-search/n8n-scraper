# .github/workflows/scrape.yml

name: Scrape Substack Search Results

# This makes the workflow runnable from n8n's API call
on:
  repository_dispatch:
    types: [n8n-trigger]

jobs:
  scrape-and-return:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Set up Node.js environment
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      # Step 2: Install Playwright library
      - name: Install Playwright library
        run: npm install playwright-core

      # --- THIS IS THE NEW STEP ---
      # Step 3: Install the browser needed by Playwright
      - name: Install Playwright Browsers
        run: npx playwright install chromium

      # Step 4: Run the scraper script for Substack
      - name: Run Playwright and Scrape Data
        id: scrape_step 
        run: |
          # Use node to execute a small script
          scraped_json=$(node -e "
            const { chromium } = require('playwright-core');
            async function run() {
              const browser = await chromium.launch();
              const page = await browser.newPage();
              await page.goto('https://substack.com/search/banjercito?searching=all_posts', { waitUntil: 'domcontentloaded' });
              
              const titles = await page.locator('[data-testid=\"post-preview-title\"]').allInnerTexts();
              await browser.close();

              return JSON.stringify(titles);
            }
            run().then(console.log);
          ")
          echo "scraped_json=$scraped_json" >> $GITHUB_OUTPUT

      # Step 5: Send the scraped data back to your n8n webhook
      - name: Send data to n8n
        run: |
          curl -X POST -H "Content-Type: application/json" \
          -d "{\"postTitles\": ${{ steps.scrape_step.outputs.scraped_json }} }" \
          "${{ secrets.N8N_WEBHOOK_URL }}"
